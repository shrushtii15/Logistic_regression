{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORcuhRro9U-J"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPuVqN77__xl"
      },
      "source": [
        "**1. What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "Logistic Regression is a classification algorithm that predicts discrete outcomes. Linear Regression is used for predicting continuous\n",
        "values. Logistic Regression uses the sigmoid function to produce probabilities.\n",
        "\n",
        "\n",
        "**2. What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "P(y=1|x) = 1 / (1 + e^-( + x + ... + x))\n",
        "\n",
        "\n",
        "**3. Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "It transforms linear outputs into probabilities (0 to 1), enabling binary classification.\n",
        "\n",
        "\n",
        "**4. What is the cost function of Logistic Regression?**\n",
        "\n",
        "J() = -1/m [y log(h(x)) + (1 - y) log(1 - h(x))]\n",
        "\n",
        "\n",
        "**5. What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "It penalizes large coefficients to reduce overfitting. L1 (Lasso) and L2 (Ridge) add penalties to the cost function.\n",
        "\n",
        "\n",
        "**6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "Lasso (L1) can shrink some coefficients to zero (feature selection). Ridge (L2) shrinks coefficients but retains all. Elastic Net\n",
        "combines both.\n",
        "\n",
        "\n",
        "**7. When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "Use when features are correlated and you want both shrinkage and feature selection.\n",
        "\n",
        "\n",
        "**8. What is the impact of the regularization parameter ( or C)?**\n",
        "\n",
        "High (low C): more regularization. Low (high C): less regularization, potential overfitting.\n",
        "\n",
        "\n",
        "**9. What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "Linearity in log-odds, no multicollinearity, independent observations, large sample size.\n",
        "\n",
        "\n",
        "**10. What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "Decision Trees, Random Forest, SVM, KNN, Gradient Boosting, Neural Networks.\n",
        "\n",
        "\n",
        "**11. What are Classification Evaluation Metrics?**\n",
        "Accuracy, Precision, Recall, F1 Score, ROC-AUC, Confusion Matrix, Log Loss.\n",
        "\n",
        "\n",
        "**12. How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "Bias toward majority class. Solutions: class weights, resampling, use F1/ROC-AUC.\n",
        "\n",
        "\n",
        "**13. What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "Adjusting parameters like C, penalty type, and solver using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "\n",
        "**14. What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "liblinear (small data, L1/L2), saga (large data, all penalties), lbfgs & newton-cg (L2, multiclass).\n",
        "\n",
        "\n",
        "**15. How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "Using One-vs-Rest (OvR) or Softmax (multinomial logistic regression).\n",
        "Logistic Regression Cheat Sheet\n",
        "\n",
        "**16. What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "Advantages: simple, interpretable, fast. Disadvantages: assumes linearity, poor on complex relationships.\n",
        "\n",
        "\n",
        "**17. What are some use cases of Logistic Regression?**\n",
        "\n",
        "Spam detection, disease diagnosis, credit scoring, churn prediction, fraud detection.\n",
        "\n",
        "\n",
        "**18. What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "Logistic: binary classification. Softmax: multiclass, outputs\n",
        "probabilities for each class.\n",
        "\n",
        "\n",
        "**19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "Softmax: exclusive classes, probability for each. OvR: simpler, works for overlapping classes.\n",
        "\n",
        "**20. How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "Each coefficient reflects change in log-odds. exp() gives the odds ratio (>1: positive impact, <1: negative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4vxnFhBBHDo"
      },
      "source": [
        "**Practical**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8UlZ1cF9TFA",
        "outputId": "b283919c-36bf-48df-8136-bb976da0a743"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "# 1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKYH37z3BS0S",
        "outputId": "879b1cca-bd63-454e-d6a9-6b5303860bff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "# 2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "welOu9PeBibK",
        "outputId": "25d3d9d2-4032-45c0-cbe8-7d552c1e491a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy 1.0\n",
            "sepal length (cm) 0.3711229016795454\n",
            "sepal width (cm) 1.4097119970148466\n",
            "petal length (cm) -2.1521011684465843\n",
            "petal width (cm) -0.9547417876562494\n"
          ]
        }
      ],
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression (penalty='12'). Print model accuracy and coefficients.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(penalty='l2', solver='liblinear', C=1.0, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Model Accuracy',accuracy_score(y_test,y_pred))\n",
        "for k in range(len(df.feature_names)):\n",
        "  print(df.feature_names[k],model.coef_[0][k])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXXmWLVQBiXl",
        "outputId": "4f31aab3-72ba-4c93-c3b9-88d99393d768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(penalty='elasticnet', solver='saga',  l1_ratio=0.5, C=1.0, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLZU3xO7BiVn",
        "outputId": "93084b39-4ab5-4612-ac46-56d457016b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(multi_class='ovr', solver='lbfgs')\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1iueNpvBiTT",
        "outputId": "69c61e13-c8f9-4f1d-ca11-1a81d671a48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
            "Best Accuracy on Test Set: 0.9912\n"
          ]
        }
      ],
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "df=load_breast_cancer()\n",
        "x=df.data\n",
        "y=df.target\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=32)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "# Grid search\n",
        "grid = GridSearchCV(model, param_grid=params, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Accuracy on Test Set: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OZOttGsBiRD",
        "outputId": "450e8929-e3d8-44c0-8f1f-a8e603952f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92982456 0.93859649 0.97368421 0.94736842 0.96460177]\n",
            "0.9508150908244062\n"
          ]
        }
      ],
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracу.\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "df=load_breast_cancer()\n",
        "\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5,)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "acc=cross_val_score(model,x,y,cv=kf)\n",
        "print(acc)\n",
        "print(np.mean(acc))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFTjwIB1ulc4",
        "outputId": "e5bd9616-f80a-48aa-f2c5-0be8f7d2fa1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample CSV created successfully.\n"
          ]
        }
      ],
      "source": [
        "# TO SAVE THE CSV FILE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Age': [22, 35, 47, 52, 23, 30, 60, 48],\n",
        "    'EstimatedSalary': [20000, 35000, 50000, 60000, 22000, 40000, 70000, 48000],\n",
        "    'Purchased': [0, 1, 1, 1, 0, 0, 1, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save it as CSV\n",
        "df.to_csv('social_network_ads.csv', index=False)\n",
        "print(\"Sample CSV created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "4YOGN1BlBiOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47d130b-ca17-4398-b666-8a66c7d807ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Age  EstimatedSalary  Purchased\n",
            "0   22            20000          0\n",
            "1   35            35000          1\n",
            "2   47            50000          1\n",
            "3   52            60000          1\n",
            "4   23            22000          0\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "# 8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its  accuracу.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('social_network_ads.csv')  # Replace with your filename\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Select Features and Target\n",
        "X = df[['Age', 'EstimatedSalary']]\n",
        "y = df['Purchased']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu7pF9TnBiMH",
        "outputId": "e66c76e7-86b7-48b0-b588-ba4704d1b3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 100, 'penalty': 'l1'}\n",
            "Best Accuracy on Test Set: 0.9825\n"
          ]
        }
      ],
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracу.\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "df=load_breast_cancer()\n",
        "x=df.data\n",
        "y=df.target\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "# Grid search\n",
        "grid = GridSearchCV(model, param_grid=params, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Accuracy on Test Set: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT-hnnjVBiJv",
        "outputId": "910e61d7-f2c5-4400-f998-3a5ba029a45c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# 10. Write a Python program to implement One-vs-One (Ovo) Multiclass Logistic Regression and print accuracy.\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = OneVsOneClassifier(LogisticRegression())\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "PHgyKHRVBiHR",
        "outputId": "ca66b121-6b16-40bf-df02-82003226511f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[77 13]\n",
            " [15 95]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "x,y=make_classification(n_samples=1000,n_features=20,n_classes=2,random_state=1)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "conf_matrix=confusion_matrix(y_test,y_pred)\n",
        "print(conf_matrix)\n",
        "sns.heatmap(conf_matrix,annot=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lGdkeG2BiE1",
        "outputId": "dc25eeb2-5a28-4de4-c667-97601e0302d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro): 0.9523809523809524\n",
            "Recall (macro): 0.9743589743589745\n",
            "F1-Score (macro): 0.9610256410256411\n"
          ]
        }
      ],
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and Fl-Score.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "#evaluate its performance using Precision, Recall, and Fl-Score.\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision = precision_score(y_test, y_pred,average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"Precision (macro):\", precision)\n",
        "print(\"Recall (macro):\", recall)\n",
        "print(\"F1-Score (macro):\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "MbKe7ihtBiCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce17e906-c154-41f4-95d9-57ed21485e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report WITHOUT class weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       183\n",
            "           1       0.94      0.88      0.91        17\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.96      0.94      0.95       200\n",
            "weighted avg       0.98      0.98      0.98       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[182   1]\n",
            " [  2  15]]\n",
            "\n",
            "Classification Report WITH class weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98       183\n",
            "           1       0.68      0.88      0.77        17\n",
            "\n",
            "    accuracy                           0.95       200\n",
            "   macro avg       0.84      0.92      0.87       200\n",
            "weighted avg       0.96      0.95      0.96       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[176   7]\n",
            " [  2  15]]\n"
          ]
        }
      ],
      "source": [
        "# 13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=6,\n",
        "                           n_redundant=2, n_clusters_per_class=1, weights=[0.9, 0.1],\n",
        "                           flip_y=0, random_state=42)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model_no_weights = LogisticRegression()\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "print(\"Classification Report WITHOUT class weights:\")\n",
        "print(classification_report(y_test, y_pred_no_weights))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_no_weights))\n",
        "\n",
        "# Train model with class weights to handle imbalance\n",
        "model_with_weights = LogisticRegression(class_weight='balanced')\n",
        "model_with_weights.fit(X_train, y_train)\n",
        "y_pred_weights = model_with_weights.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report WITH class weights:\")\n",
        "print(classification_report(y_test, y_pred_weights))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_weights))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvEDt3lBiAH",
        "outputId": "f9d8f32e-4e32-440c-db1d-3fc74db02349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8100558659217877\n",
            "0.2167310167310167\n",
            "0.803030303030303\n",
            "0.7162162162162162\n",
            "0.7571428571428571\n"
          ]
        }
      ],
      "source": [
        "# 14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "df.head()\n",
        "\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']\n",
        "target = 'survived'\n",
        "df = df[features + [target]]\n",
        "\n",
        "df['age']=df['age'].fillna(df.age.mean())\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
        "\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "print(r2)\n",
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4FBlw2tBh96",
        "outputId": "aeb0f200-553f-4567-c479-d267659aa284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy with Scaling :   0.9666666666666667\n",
            "accuracy without Scaling :   0.9666666666666667\n"
          ]
        }
      ],
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "\n",
        "  # with Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(x_train)\n",
        "X_test_scaled= scaler.transform(x_test)\n",
        "\n",
        "model=LogisticRegression()\n",
        "model.fit(X_train_scaled , y_train)\n",
        "y_pred=model.predict(X_test_scaled)\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy with Scaling :  \", acc)\n",
        "\n",
        "\n",
        "# without Standardization\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_preds=model.predict(x_test)\n",
        "\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"accuracy without Scaling :  \", acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnq-hrXLBh7l",
        "outputId": "222ee8ff-c330-40ec-bce4-74f2a4568959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc_auc_score  0.8595959595959598\n"
          ]
        }
      ],
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "x,y=make_classification(n_samples=1000,n_features=20,n_classes=2,random_state=1)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_preds=model.predict(x_test)\n",
        "\n",
        "\n",
        "roc_auc=roc_auc_score(y_test,y_preds)\n",
        "print('roc_auc_score ',roc_auc)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VApnoCYhBh5K",
        "outputId": "a85029eb-a267-445d-c73f-54342b76de41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "# 17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracу.\n",
        "from sklearn.datasets import load_iris\n",
        "df=load_iris()\n",
        "x=df.data\n",
        "y=df.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression(C=0.5)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bySlLEt8Bh21",
        "outputId": "9e1e6d97-8b9c-41c8-9216-811c18f62b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance (Model Coefficients):\n",
            "                     setosa  versicolor  virginica\n",
            "sepal length (cm) -0.393456    0.508433  -0.114977\n",
            "sepal width (cm)   0.962518   -0.254827  -0.707691\n",
            "petal length (cm) -2.375124   -0.213011   2.588136\n",
            "petal width (cm)  -0.998746   -0.775748   1.774494\n"
          ]
        }
      ],
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model (one-vs-rest by default)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get model coefficients\n",
        "coefficients = model.coef_  # shape: [n_classes, n_features]\n",
        "\n",
        "coeff_df = pd.DataFrame(coefficients.T, index=feature_names, columns=target_names)\n",
        "\n",
        "print(\"Feature Importance (Model Coefficients):\")\n",
        "print(coeff_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsVop-GQBh0v",
        "outputId": "b1132993-507b-4069-efa2-ad60b6c80089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate with Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print result\n",
        "print(\"Cohen's Kappa Score:\",kappa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "6C-wK6HCBhyU",
        "outputId": "69811ee8-7d5e-494d-f24a-04b66326f021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n",
        "\n",
        "# Import required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Load binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target  # Binary: 0 (malignant), 1 (benign)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for positive class\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute precision-recall values\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "average_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {average_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (Logistic Regression)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP3SIOp0BhwA",
        "outputId": "71624cc2-28ed-45a7-ceea-6dd9a76de715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver Comparison:\n",
            "liblinear: 1.0\n",
            "saga: 1.0\n",
            "lbfgs: 1.0\n"
          ]
        }
      ],
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, Ibfgs) and compare their accuracy.\n",
        "\n",
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracies = {}\n",
        "\n",
        "# Train and evaluate Logistic Regression with each solver\n",
        "for solver in solvers:\n",
        "\n",
        "        model = LogisticRegression(solver=solver, max_iter=200)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies[solver] = acc\n",
        "\n",
        "\n",
        "# Print accuracy for each solver\n",
        "print(\"Solver Comparison:\")\n",
        "for solver, acc in accuracies.items():\n",
        "    print(f\"{solver}: {acc}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTib1OPNBht1",
        "outputId": "29f88bca-99fc-42c7-9c0f-4fff528027ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matthews_corrcoef 1.0\n"
          ]
        }
      ],
      "source": [
        "# 22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "coef=matthews_corrcoef(y_pred,y_test)\n",
        "print('matthews_corrcoef',coef)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n60QB4ocBhrn",
        "outputId": "ad492628-e3ae-41fb-fab2-3cea981008e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Raw Data        : 0.956140350877193\n",
            "Accuracy on Standardized Data: 0.9736842105263158\n"
          ]
        }
      ],
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# raw dATA\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "#on Standardized Data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "\n",
        "print(\"Accuracy on Raw Data        :\", acc_raw)\n",
        "print(\"Accuracy on Standardized Data:\",acc_scaled  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b-QqLiBho9",
        "outputId": "e2642fcc-a87c-4d56-fcaf-ed482acce58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value from cross-validation: 1\n",
            "Test set accuracy with best C     : 0.9825\n"
          ]
        }
      ],
      "source": [
        "# 24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "#  parameter grid for C (regularization strength)\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Perform cross-validation using GridSearchCV\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "best_C = grid_search.best_params_['C']\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best C value from cross-validation:\", best_C)\n",
        "print(\"Test set accuracy with best C     :\", round(accuracy, 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yra0WB4Bhmp",
        "outputId": "c84b15dd-a49c-43a1-fe6b-cf6c1dfb08a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'logistic_model.joblib'\n",
            "Model loaded successfully.\n",
            "Predicted class for sample: 1 (versicolor)\n"
          ]
        }
      ],
      "source": [
        "# 25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "# Import libraries\n",
        "import joblib\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model to a file\n",
        "joblib.dump(model, 'logistic_model.joblib')\n",
        "print(\"Model saved as 'logistic_model.joblib'\")\n",
        "\n",
        "# Load model from file\n",
        "loaded_model = joblib.load('logistic_model.joblib')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Predict using loaded model\n",
        "sample = X_test[0].reshape(1, -1)\n",
        "predicted_class = loaded_model.predict(sample)[0]\n",
        "print(f\"Predicted class for sample: {predicted_class} ({iris.target_names[predicted_class]})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "CshbpZwOBhWP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}